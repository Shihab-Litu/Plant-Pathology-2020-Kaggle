{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Conv2D, BatchNormalization,MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D,Conv2DTranspose\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau \n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(\"images\")\n",
    "\n",
    "train = [t for t in images if \"Train\" in t]\n",
    "test = [t for t in images if \"Test\" in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "test_csv = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "\n",
    "for i in train_csv[\"image_id\"]:\n",
    "    img = cv2.imread(\"images/\"+i+\".jpg\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (150,150),interpolation=cv2.INTER_AREA)\n",
    "    train_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_csv.drop('image_id',axis=1)\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 150, 150, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X/255.0    \n",
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train,y_val = train_test_split(X,y,test_size = .20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "# x_smote, y_smote = sm.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': [424  72 490 470]\n",
      "Before OverSampling, counts of label '0': [1032 1384  966  986] \n",
      "\n",
      "After OverSampling, the shape of train_X: (1960, 67500)\n",
      "After OverSampling, the shape of train_y: (1960, 4) \n",
      "\n",
      "After OverSampling, counts of label '1': [490 490 490 490]\n",
      "After OverSampling, counts of label '0': [1470 1470 1470 1470]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x_smote, y_smote = sm.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train)\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(x_smote.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_smote.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_smote==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_smote==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model() :\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #Block 1\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu',input_shape=(150,150,3)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #Block 2\n",
    "    \n",
    "    model.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #Block 3\n",
    "    \n",
    "    model.add(Conv2D(256,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "    model.add(Conv2D(256,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "    model.add(Conv2D(256,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #Block 4 \n",
    "    \n",
    "    model.add(Conv2D(512,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(512,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(512,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.2))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Block 5\n",
    "    \n",
    "    model.add(Conv2D(1024,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(1024,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    \n",
    "    #Final Block\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "        \n",
    "    #Compile\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shihab\\Anaconda3\\envs\\shihab\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\shihab\\Anaconda3\\envs\\shihab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 75, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 35, 35, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 33, 33, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 31, 31, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 31, 31, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 15, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 26,836,996\n",
      "Trainable params: 26,833,028\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = construct_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smote = x_smote.reshape(x_smote.shape[0], 150, 150, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shihab\\Anaconda3\\envs\\shihab\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1960/1960 [==============================] - 58s 30ms/step - loss: 5.7368 - acc: 0.2760\n",
      "Epoch 2/5\n",
      "1960/1960 [==============================] - 48s 24ms/step - loss: 3.2562 - acc: 0.2827\n",
      "Epoch 3/5\n",
      "1960/1960 [==============================] - 48s 25ms/step - loss: 1.5821 - acc: 0.2913\n",
      "Epoch 4/5\n",
      "1960/1960 [==============================] - 48s 25ms/step - loss: 1.4274 - acc: 0.3204\n",
      "Epoch 5/5\n",
      "1960/1960 [==============================] - 49s 25ms/step - loss: 1.3325 - acc: 0.3862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22fdf9a7da0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_smote, y_smote, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range = 40,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"./Data/Train/\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=4,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=r\"./Data/Validation/\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=4,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     directory=r\"./Data/Test/\",\n",
    "#     target_size=(150, 150),\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=1,\n",
    "#     class_mode=None,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             epochs = 10,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps= STEP_SIZE_VALID,\n",
    "                            callbacks = [model_checkpoint, early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
